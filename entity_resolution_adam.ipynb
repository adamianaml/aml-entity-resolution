{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ama = pd.read_csv('./data/amazon.csv')\n",
    "rt = pd.read_csv('./data/rotten_tomatoes.csv')\n",
    "\n",
    "holdout = pd.read_csv('./data/holdout.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "train = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ama.columns = [\n",
    "    'id_left',\n",
    "    'time_left',\n",
    "    'director_left',\n",
    "    'star_left',\n",
    "    'cost_left'\n",
    "]\n",
    "\n",
    "rt.columns = [\n",
    "    'id_right',\n",
    "    'time_right',\n",
    "    'director_right',\n",
    "    'year_right',\n",
    "    'star1_right',\n",
    "    'star2_right',\n",
    "    'star3_right',\n",
    "    'star4_right',\n",
    "    'star5_right',\n",
    "    'star6_right',\n",
    "    'rotten_tomatoes_right',\n",
    "    'audience_rating_right',\n",
    "    'review1_right',\n",
    "    'review2_right',\n",
    "    'review3_right',\n",
    "    'review4_right',\n",
    "    'review5_right'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Ama + Rt and Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1037,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_features(dataset):\n",
    "    new_data = pd.DataFrame(dtype=str)\n",
    "    \n",
    "    for index, row in dataset.iterrows():\n",
    "        amarow = ama[ama['id_left'] == row['id1']]\n",
    "        rtrow = rt[rt['id_right'] == row['id 2']]\n",
    "\n",
    "        amarow.reset_index(drop=True, inplace=True)\n",
    "        rtrow.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        new_row = pd.concat([amarow, rtrow], axis=1)\n",
    "        new_data = pd.concat([new_data, new_row])\n",
    "    \n",
    "    new_data.fillna('0', inplace = True)\n",
    "    new_data.dropna()\n",
    "    \n",
    "    # Compute directors match column\n",
    "    new_data['directors_same'] = (new_data['director_left'] == new_data['director_right']).astype(int)\n",
    "    \n",
    "    # Compute time columns\n",
    "    new_data['time_left'] = new_data['time_left'].astype(str)\n",
    "    new_data['time_right'] = new_data['time_right'].astype(str)\n",
    "    new_data['time_norm_left'] = new_data['time_left'].apply(compute_time_norm)\n",
    "    new_data['time_norm_right'] = new_data['time_right'].apply(compute_time_norm)\n",
    "    new_data['time_same'] = (new_data['time_norm_left'].astype(int) == new_data['time_norm_right'].astype(int)).astype(int)\n",
    "    new_data['time_same_2'] = (abs((new_data['time_norm_left'].astype(int) - new_data['time_norm_right'].astype(int)).astype(int)) <= 3).astype(int)\n",
    "    new_data['time_diff'] = (new_data['time_norm_left'].astype(int) - new_data['time_norm_right'].astype(int)).astype(int)\n",
    "    new_data['time_diff_abs'] = abs(new_data['time_diff']).astype(int)\n",
    "    \n",
    "    # Compute actors columns\n",
    "    actors_split = new_data['star_left'].str.split(', ', expand=True)\n",
    "    for i in range(6 - actors_split.shape[1]):\n",
    "        actors_split[str(i)] = \"\"\n",
    "    actors_split.columns = ['star_' + str(i) for i in range(6)]\n",
    "    new_data = pd.concat([new_data, actors_split], axis=1)\n",
    "    \n",
    "    # Number actors match\n",
    "    cols = list(new_data.loc[:,'star_0':'star_4']) + list(new_data.loc[:,'star1_right':'star6_right'])\n",
    "    new_data['num_match_stars'] = new_data[cols].apply(compute_number_stars_match, axis = 1)\n",
    "    \n",
    "    # Percent actors match\n",
    "    new_data['percent_match_stars'] = new_data[cols].apply(compute_percent_stars_match, axis = 1)\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_number_stars_match(row):\n",
    "    actors_left = ['star_0', 'star_1', 'star_2', 'star_3', 'star_4']\n",
    "    actors_right = ['star1_right', 'star2_right', 'star3_right', 'star4_right', 'star5_right', 'star6_right']\n",
    "    list_left = row.loc[actors_left].tolist()\n",
    "    list_right = row.loc[actors_right].tolist()\n",
    "    \n",
    "    # Avoid matching nulls\n",
    "    list_left = filter(None, list_left)\n",
    "    list_right = filter(None, list_right)\n",
    "    \n",
    "    return len(np.intersect1d(list_left, list_right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_percent_stars_match(row):\n",
    "    actors_left = ['star_0', 'star_1', 'star_2', 'star_3', 'star_4']\n",
    "    actors_right = ['star1_right', 'star2_right', 'star3_right', 'star4_right', 'star5_right', 'star6_right']\n",
    "    list_left = row.loc[actors_left].tolist()\n",
    "    list_left = filter(None, list_left)\n",
    "    list_right = row.loc[actors_right].tolist()\n",
    "    x = float(len(np.intersect1d(list_left, list_right)))\n",
    "    ama_num = len(list_left)\n",
    "    return x / ama_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regex = re.compile(r'[0-9]*')\n",
    "\n",
    "def compute_time_norm(row):\n",
    "    row = str(row)\n",
    "    \n",
    "    if '/' in row:\n",
    "        # Invalid time entry\n",
    "        print(row)\n",
    "        return 0\n",
    "    \n",
    "    match = regex.findall(row)\n",
    "    temp = filter(None, match)\n",
    "    if len(temp) == 2:\n",
    "        return 60*int(temp[0]) + int(temp[1])\n",
    "    if len(temp) == 1:\n",
    "        return temp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_bad_samples(data):\n",
    "    \n",
    "    train.reset_index(drop=True, inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    data = pd.concat([data, train], axis=1)\n",
    "    \n",
    "    # Remove bad training rows\n",
    "    data = data[data['id_left'] != 199]\n",
    "    data = data[data['id_left'] != 680]\n",
    "    data = data[data['id_left'] != 487]\n",
    "    data = data[data['id_left'] != 756]\n",
    "    data = data[data['id_left'] != 770]\n",
    "    data = data[data['id_left'] != 1701]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features_cols = [\n",
    "#     'time_diff',\n",
    "#     'time_same',\n",
    "    'time_same_2',\n",
    "#     'time_diff_abs',\n",
    "    'directors_same',\n",
    "    'num_match_stars',\n",
    "    'percent_match_stars',\n",
    "#     'year_right',\n",
    "#     'rotten_tomatoes_right',\n",
    "#     'audience_rating_right'\n",
    "]\n",
    "\n",
    "train_data = create_features(train)\n",
    "train_data = remove_bad_samples(train_data)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_data[features_cols], train_data['gold'])\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "scores = clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96        52\n",
      "          1       0.86      0.67      0.75         9\n",
      "\n",
      "avg / total       0.93      0.93      0.93        61\n",
      "\n",
      "Error inds: [10 21 23 49]\n",
      "Preds: [0 0 1 0]\n",
      "Labels: [1 1 0 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_same_2</th>\n",
       "      <th>directors_same</th>\n",
       "      <th>num_match_stars</th>\n",
       "      <th>percent_match_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     time_same_2  directors_same  num_match_stars  percent_match_stars\n",
       "154            0               1                2                  1.0\n",
       "137            1               1                1                  0.5\n",
       "209            1               1                1                  1.0\n",
       "122            1               1                1                  0.5"
      ]
     },
     "execution_count": 1145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = clf.predict(x_test)\n",
    "\n",
    "# F1 score:\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, preds))\n",
    "\n",
    "# Missed preds:\n",
    "errors = preds - y_test\n",
    "error_ind = np.nonzero(errors)[0]\n",
    "\n",
    "print(\"Error inds: \" + str(error_ind))\n",
    "print(\"Preds: \" + str(preds[error_ind]))\n",
    "print(\"Labels: \" + str(y_test.as_matrix()[error_ind]))\n",
    "\n",
    "rel_cols = ['director_left', 'time_right', 'directors_same', 'time_same', 'time_diff', 'num_match_stars', 'gold']\n",
    "x_test.iloc[error_ind]\n",
    "\n",
    "# Conf matrix:\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = create_features(train)\n",
    "train_data = remove_bad_samples(train_data)\n",
    "test_data = create_features(test)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(train_data[features_cols], train_data['gold'])\n",
    "test_preds = clf.predict(test_data[features_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_preds = pd.DataFrame(test_preds)\n",
    "test_preds.columns = ['gold']\n",
    "test_preds.to_csv('test_gold.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = create_features(train)\n",
    "train_data = remove_bad_samples(train_data)\n",
    "holdout_data = create_features(holdout)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(train_data[features_cols], train_data['gold'])\n",
    "holdout_preds = clf.predict(holdout_data[features_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "holdout_preds = pd.DataFrame(holdout_preds)\n",
    "holdout_preds.columns = ['gold']\n",
    "holdout_preds.to_csv('holdout_gold.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try all combinations of features / classifiers / removing bad data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, ('time_same_2', 'time_diff_abs'), True, 'RandomForestClassifier', 0.88650793650793647]\n",
      "[2, ('time_same_2', 'time_diff_abs'), True, 'GradientBoostingClassifier', 0.98412698412698418]\n",
      "[2, ('time_same_2', 'time_diff_abs'), False, 'RandomForestClassifier', 0.9365079365079364]\n",
      "[2, ('time_same_2', 'time_diff_abs'), False, 'GradientBoostingClassifier', 0.95079365079365064]\n",
      "[2, ('time_same_2', 'num_match_stars'), True, 'RandomForestClassifier', 0.93492063492063482]\n",
      "[2, ('time_same_2', 'num_match_stars'), True, 'GradientBoostingClassifier', 0.98333333333333339]\n",
      "[2, ('time_same_2', 'num_match_stars'), False, 'RandomForestClassifier', 1.0]\n",
      "[2, ('time_same_2', 'num_match_stars'), False, 'GradientBoostingClassifier', 0.93333333333333324]\n",
      "[2, ('time_same_2', 'percent_match_stars'), True, 'RandomForestClassifier', 0.93492063492063482]\n",
      "[2, ('time_same_2', 'percent_match_stars'), True, 'GradientBoostingClassifier', 0.96825396825396826]\n",
      "[2, ('time_same_2', 'percent_match_stars'), False, 'RandomForestClassifier', 0.93492063492063482]\n",
      "[2, ('time_same_2', 'percent_match_stars'), False, 'GradientBoostingClassifier', 0.98333333333333339]\n",
      "[2, ('time_diff_abs', 'num_match_stars'), True, 'RandomForestClassifier', 1.0]\n",
      "[2, ('time_diff_abs', 'num_match_stars'), True, 'GradientBoostingClassifier', 0.95071010860484539]\n",
      "[2, ('time_diff_abs', 'num_match_stars'), False, 'RandomForestClassifier', 0.93492063492063482]\n",
      "[2, ('time_diff_abs', 'num_match_stars'), False, 'GradientBoostingClassifier', 0.98333333333333339]\n",
      "[2, ('time_diff_abs', 'percent_match_stars'), True, 'RandomForestClassifier', 0.96746031746031746]\n",
      "[2, ('time_diff_abs', 'percent_match_stars'), True, 'GradientBoostingClassifier', 0.96825396825396826]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/sklearn/cross_validation.py:552: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, ('time_diff_abs', 'percent_match_stars'), False, 'RandomForestClassifier', 0.95238095238095244]\n",
      "[2, ('time_diff_abs', 'percent_match_stars'), False, 'GradientBoostingClassifier', 0.98333333333333339]\n",
      "[2, ('num_match_stars', 'percent_match_stars'), True, 'RandomForestClassifier', 0.95079365079365064]\n",
      "[2, ('num_match_stars', 'percent_match_stars'), True, 'GradientBoostingClassifier', 0.93412698412698403]\n",
      "[2, ('num_match_stars', 'percent_match_stars'), False, 'RandomForestClassifier', 0.884920634920635]\n",
      "[2, ('num_match_stars', 'percent_match_stars'), False, 'GradientBoostingClassifier', 0.95238095238095244]\n",
      "[3, ('time_same_2', 'time_diff_abs', 'num_match_stars'), True, 'RandomForestClassifier', 0.98333333333333339]\n",
      "[3, ('time_same_2', 'time_diff_abs', 'num_match_stars'), True, 'GradientBoostingClassifier', 0.96658312447786132]\n",
      "[3, ('time_same_2', 'time_diff_abs', 'num_match_stars'), False, 'RandomForestClassifier', 0.93412698412698403]\n",
      "[3, ('time_same_2', 'time_diff_abs', 'num_match_stars'), False, 'GradientBoostingClassifier', 0.91896407685881354]\n",
      "[3, ('time_same_2', 'time_diff_abs', 'percent_match_stars'), True, 'RandomForestClassifier', 0.96666666666666667]\n",
      "[3, ('time_same_2', 'time_diff_abs', 'percent_match_stars'), True, 'GradientBoostingClassifier', 0.93492063492063482]\n",
      "[3, ('time_same_2', 'time_diff_abs', 'percent_match_stars'), False, 'RandomForestClassifier', 0.91896407685881354]\n",
      "[3, ('time_same_2', 'time_diff_abs', 'percent_match_stars'), False, 'GradientBoostingClassifier', 0.919047619047619]\n",
      "[3, ('time_same_2', 'num_match_stars', 'percent_match_stars'), True, 'RandomForestClassifier', 0.95079365079365064]\n",
      "[3, ('time_same_2', 'num_match_stars', 'percent_match_stars'), True, 'GradientBoostingClassifier', 0.90079365079365081]\n",
      "[3, ('time_same_2', 'num_match_stars', 'percent_match_stars'), False, 'RandomForestClassifier', 0.95079365079365064]\n",
      "[3, ('time_same_2', 'num_match_stars', 'percent_match_stars'), False, 'GradientBoostingClassifier', 0.93316624895572264]\n",
      "[3, ('time_diff_abs', 'num_match_stars', 'percent_match_stars'), True, 'RandomForestClassifier', 0.95238095238095244]\n",
      "[3, ('time_diff_abs', 'num_match_stars', 'percent_match_stars'), True, 'GradientBoostingClassifier', 0.91984126984126979]\n",
      "[3, ('time_diff_abs', 'num_match_stars', 'percent_match_stars'), False, 'RandomForestClassifier', 0.96825396825396826]\n",
      "[3, ('time_diff_abs', 'num_match_stars', 'percent_match_stars'), False, 'GradientBoostingClassifier', 0.91896407685881376]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "features = [\n",
    "    'directors_same',\n",
    "]\n",
    "\n",
    "features_opt = [\n",
    "    'time_same_2',\n",
    "    'time_diff_abs',\n",
    "    'num_match_stars',\n",
    "    'percent_match_stars',\n",
    "]\n",
    "\n",
    "remove_bad_data = [True, False]\n",
    "\n",
    "classifiers = [\n",
    "#     DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    GradientBoostingClassifier()\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for r in range(2, len(features_opt)):\n",
    "    for feature_comb in itertools.combinations(features_opt, r):\n",
    "        for remove_bd in remove_bad_data:\n",
    "            for clf in classifiers:\n",
    "                \n",
    "                train_data = create_features(train)\n",
    "                \n",
    "                if remove_bd:\n",
    "                    train_data = remove_bad_samples(train_data)\n",
    "\n",
    "                x_train, x_test, y_train, y_test = train_test_split(train_data[list(feature_comb) + features], train_data['gold'])\n",
    "\n",
    "                clf.fit(x_train, y_train)\n",
    "                scores = cross_val_score(clf, x_test, y_test)\n",
    "                \n",
    "                res = [r, feature_comb, remove_bd, type(clf).__name__, scores.mean()]\n",
    "                print(res)\n",
    "                results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results_csv = pd.DataFrame(results)\n",
    "results_csv.columns = ['r', 'features', 'remove_bd', 'clf', 'scores']\n",
    "results_csv.to_csv('choosing_final_classifier.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.88492063,  0.88650794,  0.90079365,  0.91896408,  0.91896408,\n",
       "        0.91904762,  0.91984127,  0.93316625,  0.93333333,  0.93412698,\n",
       "        0.93492063,  0.93650794,  0.95071011,  0.95079365,  0.95238095,\n",
       "        0.96658312,  0.96666667,  0.96746032,  0.96825397,  0.98333333,\n",
       "        0.98412698,  1.        ])"
      ]
     },
     "execution_count": 1070,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(results_csv['scores'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing best results from^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_feats = ['directors_same', 'time_same_2', 'num_match_stars', 'percent_match_stars']\n",
    "\n",
    "train_data = create_features(train)\n",
    "train_data = remove_bad_samples(train_data)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_data[final_feats], train_data['gold'])\n",
    "\n",
    "RandomForestClassifier().fit(x_train, y_train)\n",
    "scores = cross_val_score(clf, x_test, y_test, cv=3)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
