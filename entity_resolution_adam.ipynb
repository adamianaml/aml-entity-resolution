{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ama = pd.read_csv('./data/amazon.csv')\n",
    "rt = pd.read_csv('./data/rotten_tomatoes.csv')\n",
    "\n",
    "holdout = pd.read_csv('./data/holdout.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "train = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ama.columns = [\n",
    "    'id_left',\n",
    "    'time_left',\n",
    "    'director_left',\n",
    "    'star_left',\n",
    "    'cost_left'\n",
    "]\n",
    "\n",
    "rt.columns = [\n",
    "    'id_right',\n",
    "    'time_right',\n",
    "    'director_right',\n",
    "    'year_right',\n",
    "    'star1_right',\n",
    "    'star2_right',\n",
    "    'star3_right',\n",
    "    'star4_right',\n",
    "    'star5_right',\n",
    "    'star6_right',\n",
    "    'rotten_tomatoes_right',\n",
    "    'audience_rating_right',\n",
    "    'review1_right',\n",
    "    'review2_right',\n",
    "    'review3_right',\n",
    "    'review4_right',\n",
    "    'review5_right'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge records from ama and rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_features(dataset):\n",
    "    new_data = pd.DataFrame(dtype=str)\n",
    "    \n",
    "    for index, row in dataset.iterrows():\n",
    "        amarow = ama[ama['id_left'] == row['id1']]\n",
    "        rtrow = rt[rt['id_right'] == row['id 2']]\n",
    "\n",
    "        amarow.reset_index(drop=True, inplace=True)\n",
    "        rtrow.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        new_row = pd.concat([amarow, rtrow], axis=1)\n",
    "        new_data = pd.concat([new_data, new_row])\n",
    "    \n",
    "    new_data.fillna('0', inplace = True)\n",
    "    new_data.dropna()\n",
    "    \n",
    "    # Compute directors match column\n",
    "    new_data['directors_same'] = (new_data['director_left'] == new_data['director_right']).astype(int)\n",
    "    \n",
    "    # Compute time columns\n",
    "    new_data['time_left'] = new_data['time_left'].astype(str)\n",
    "    new_data['time_right'] = new_data['time_right'].astype(str)\n",
    "\n",
    "    new_data['time_norm_left'] = new_data['time_left'].apply(compute_time_norm)\n",
    "    new_data['time_norm_right'] = new_data['time_right'].apply(compute_time_norm)\n",
    "    new_data['time_same'] = (new_data['time_norm_left'].astype(int) == new_data['time_norm_right'].astype(int)).astype(int)\n",
    "    new_data['time_diff'] = (new_data['time_norm_left'].astype(int) - new_data['time_norm_right'].astype(int)).astype(int)\n",
    "    \n",
    "    # Compute actors columns\n",
    "    actors_split = new_data['star_left'].str.split(', ', expand=True)\n",
    "    actors_split_columns = ['star_' + str(i) for i in range(len(actors_split.columns))]\n",
    "    actors_split.columns = actors_split_columns\n",
    "    new_data = pd.concat([new_data, actors_split], axis=1)\n",
    "    \n",
    "    # Todo - fix for > 2 stars_left\n",
    "    cols = list(new_data.loc[:,'star_0':'star_4']) + list(new_data.loc[:,'star1_right':'star6_right'])\n",
    "    new_data['num_match_stars'] = new_data[cols].apply(compute_number_stars_match, axis = 1)\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_data_copy = create_features(train)\n",
    "\n",
    "actors_split = train_data_copy['star_left'].str.split(', ', expand=True)\n",
    "actors_split_columns = ['star_' + str(i) for i in range(len(actors_split.columns))]\n",
    "actors_split.columns = actors_split_columns\n",
    "train_data_copy = pd.concat([train_data_copy, actors_split], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_number_stars_match(row):\n",
    "    actors_left = ['star_0', 'star_1', 'star_2', 'star_3', 'star_4']\n",
    "    actors_right = ['star1_right', 'star2_right', 'star3_right', 'star4_right', 'star5_right', 'star6_right']\n",
    "    list_left = row.loc[actors_left].tolist()\n",
    "    list_right = row.loc[actors_right].tolist()\n",
    "    x = len(np.intersect1d(list_left, list_right))\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regex = re.compile(r'[0-9]*')\n",
    "\n",
    "def compute_time_norm(row):\n",
    "    row = str(row)\n",
    "    match = regex.findall(row)\n",
    "    temp = filter(None, match)\n",
    "    if len(temp) == 2:\n",
    "        return 60*int(temp[0]) + int(temp[1])\n",
    "    if len(temp) == 1:\n",
    "        return temp[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.967741935483871"
      ]
     },
     "execution_count": 850,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cols = ['time_diff', 'directors_same', 'num_match_stars']\n",
    "\n",
    "train_data = create_features(train)\n",
    "\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_data = pd.concat([train_data, train], axis=1) #, how='inner')\n",
    "\n",
    "# Remove bad training rows\n",
    "train_data = train_data[train_data['id_left'] != 199]\n",
    "train_data = train_data[train_data['id_left'] != 680]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_data[features_cols], train_data['gold'])\n",
    "\n",
    "clf = GradientBoostingClassifier(min_samples_split=10)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 18])"
      ]
     },
     "execution_count": 857,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1]\n",
      "[0 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_diff</th>\n",
       "      <th>directors_same</th>\n",
       "      <th>num_match_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    time_diff  directors_same  num_match_stars\n",
       "96          0               1                1\n",
       "10          5               1                1"
      ]
     },
     "execution_count": 855,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=200)\n",
    "clf.fit(x_train, y_train)\n",
    "preds = clf.predict(x_test)\n",
    "\n",
    "# Missed preds:\n",
    "errors = preds - y_test\n",
    "error_ind = np.nonzero(errors)[0]\n",
    "\n",
    "print(preds[error_ind])\n",
    "print(y_test.as_matrix()[error_ind])\n",
    "\n",
    "rel_cols = ['director_left', 'time_right', 'directors_same', 'time_same', 'time_diff', 'num_match_stars', 'gold']\n",
    "x_test.iloc[error_ind]\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_cols = ['time_same'] + ['directors_same'] + ['num_match_stars']\n",
    "test_data = create_features(test)\n",
    "\n",
    "clf = GradientBoostingClassifier(min_samples_split=10)\n",
    "clf.fit(train_data[features_cols], train_data['gold'])\n",
    "test_preds = clf.predict(test_data[features_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_preds = pd.DataFrame(test_preds)\n",
    "test_preds.columns = ['gold']\n",
    "test_preds.to_csv('test_gold.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_cols = ['time_same'] + ['directors_same'] + ['num_match_stars']\n",
    "holdout_data = create_features(holdout)\n",
    "\n",
    "clf = GradientBoostingClassifier(min_samples_split=10)\n",
    "clf.fit(train_data[features_cols], train_data['gold'])\n",
    "holdout_preds = clf.predict(holdout_data[features_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "holdout_preds = pd.DataFrame(holdout_preds)\n",
    "holdout_preds.columns = ['gold']\n",
    "holdout_preds.to_csv('holdout_gold.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
