{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ama = pd.read_csv('./data/amazon.csv')\n",
    "rt = pd.read_csv('./data/rotten_tomatoes.csv')\n",
    "\n",
    "holdout = pd.read_csv('./data/holdout.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "train = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ama.columns = [\n",
    "    'id_left',\n",
    "    'time_left',\n",
    "    'director_left',\n",
    "    'star_left',\n",
    "    'cost_left'\n",
    "]\n",
    "\n",
    "rt.columns = [\n",
    "    'id_right',\n",
    "    'time_right',\n",
    "    'director_right',\n",
    "    'year_right',\n",
    "    'star1_right',\n",
    "    'star2_right',\n",
    "    'star3_right',\n",
    "    'star4_right',\n",
    "    'star5_right',\n",
    "    'star6_right',\n",
    "    'rotten_tomatoes_right',\n",
    "    'audience_rating_right',\n",
    "    'review1_right',\n",
    "    'review2_right',\n",
    "    'review3_right',\n",
    "    'review4_right',\n",
    "    'review5_right'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge records from ama and rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_features(dataset):\n",
    "    new_data = pd.DataFrame(dtype=str)\n",
    "    \n",
    "    for index, row in dataset.iterrows():\n",
    "\n",
    "        amarow = ama[ama['id_left'] == row['id1']]\n",
    "        rtrow = rt[rt['id_right'] == row['id 2']]\n",
    "\n",
    "        amarow.reset_index(drop=True, inplace=True)\n",
    "        rtrow.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        new_row = pd.concat([amarow, rtrow], axis=1)\n",
    "        new_data = pd.concat([new_data, new_row])\n",
    "    \n",
    "    new_data.fillna('0', inplace = True)\n",
    "    new_data.dropna()\n",
    "    \n",
    "    # Compute directors match column\n",
    "    new_data['directors_same'] = (new_data['director_left'] == new_data['director_right']).astype(int)\n",
    "    \n",
    "    # Compute time columns\n",
    "    new_data['time_left'] = new_data['time_left'].astype(str)\n",
    "    new_data['time_right'] = new_data['time_right'].astype(str)\n",
    "\n",
    "    new_data['time_norm_left'] = new_data['time_left'].apply(compute_time_norm)\n",
    "    new_data['time_norm_right'] = new_data['time_right'].apply(compute_time_norm)\n",
    "    new_data['time_same'] = (new_data['time_norm_left'] == new_data['time_norm_right']).astype(int)\n",
    "    new_data['time_diff'] = (new_data['time_norm_left'].astype(int) - new_data['time_norm_right'].astype(int))\n",
    "    \n",
    "    # Compute actors columns\n",
    "    actors_split = new_data['star_left'].str.split(', ', expand=True)\n",
    "    actors_split_columns = ['star_' + str(i) for i in range(len(actors_split.columns))]\n",
    "    actors_split.columns = actors_split_columns\n",
    "    new_data = pd.concat([new_data, actors_split], axis=1)\n",
    "    \n",
    "    # Todo - fix for > 2 stars_left\n",
    "    cols = list(new_data.loc[:,'star_0':'star_1']) + list(new_data.loc[:,'star1_right':'star6_right'])\n",
    "    new_data['num_match_stars'] = new_data[cols].apply(compute_number_stars_match, axis = 1)\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regex = re.compile(r'[0-9]*')\n",
    "\n",
    "def compute_time_norm(row):\n",
    "    row = str(row)\n",
    "    match = regex.findall(row)\n",
    "    temp = filter(None, match)\n",
    "    if len(temp) == 2:\n",
    "        return 60*int(temp[0]) + int(temp[1])\n",
    "    if len(temp) == 1:\n",
    "        return temp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_number_stars_match(row):\n",
    "    list_left = row[:5].tolist()\n",
    "    list_right = row[5:].tolist()\n",
    "    x = len(np.intersect1d(list_left, list_right))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90322580645161288"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cols = ['time_same'] + ['directors_same'] + ['num_match_stars']\n",
    "\n",
    "train_data = create_features(train)\n",
    "\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_data = pd.concat([train_data, train], axis=1) #, how='inner')\n",
    "\n",
    "# Remove bad training rows\n",
    "train_data = train_data[train_data['id_left'] != 199]\n",
    "train_data = train_data[train_data['id_left'] != 680]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_data[features_cols], train_data['gold'])\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_cols = ['time_left', 'time_right', 'time_same', 'time_diff', 'time_norm_left', 'time_norm_right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find missed predictions\n",
    "\n",
    "preds = clf.predict(test)\n",
    "\n",
    "errors = preds - y_test.as_matrix()\n",
    "error_inds = np.nonzero(errors)\n",
    "\n",
    "error_rows = new_data.copy().as_matrix()[error_inds]\n",
    "error_rows = pd.DataFrame(error_rows)\n",
    "error_rows.columns = new_data.columns\n",
    "\n",
    "error_preds = pd.DataFrame(preds[error_inds], columns=['pred'])\n",
    "w_preds = pd.concat([error_rows, error_preds], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_cols = ['time_same'] + ['directors_same'] + ['num_match_stars']\n",
    "test_data = create_features(test)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(train_data[features_cols], train_data['gold'])\n",
    "test_preds = clf.predict(test_data[features_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_preds = pd.DataFrame(test_preds)\n",
    "test_preds.columns = ['gold']\n",
    "test_preds.to_csv('test_gold.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_cols = ['time_same'] + ['directors_same'] + ['num_match_stars']\n",
    "holdout_data = create_features(holdout)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(train_data[features_cols], train_data['gold'])\n",
    "holdout_preds = clf.predict(holdout_data[features_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "holdout_preds = pd.DataFrame(holdout_preds)\n",
    "holdout_preds.columns = ['gold']\n",
    "holdout_preds.to_csv('holdout_gold.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
